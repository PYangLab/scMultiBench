patchseq_config = {
    "train_batch_size": 16,
    "finetune_batch_size": 16,
    "transfer_batch_size": None,
    "train_epochs": 20,
    "finetune_epochs": 20,
    "transfer_epochs": None,
    "train_task": "cross_model_prediction_clus",  # "cross_model_prediction_clus",
    "finetune_task": "unsupervised_group_identification",
    "transfer_task": None,
    "train_loss_weight": None,
    "finetune_loss_weight": None,
    "transfer_loss_weight": None,
    "lr": 0.001,
    "checkpoint": 1,
    "n_head": 10,
    "fuser_type": "WeightedFeatureMean",
    "noise_level":[0,0,0.01],
    "encoders": [
        {
            "input": 1252,
            "hiddens": [1024, 512, 256, 128],
            "output": 68,
            "use_biases": [True, True, True, True, True],
            "dropouts": [0.5, 0, 0, 0, 0],
            "activations": ["relu", "relu", "relu", "relu", None],
            "use_batch_norms": [False, False, False, False, False],
            "use_layer_norms": [False, False, False, False, True],
            "is_binary_input": False,
        },
        {
            "input": 68,
            "hiddens": [1024, 512, 256, 128],
            "output": 68,
            "use_biases": [True, True, True, True, True],
            "dropouts": [0, 0, 0, 0, 0],
            "activations": ["relu", "relu", "relu", "relu", None],
            "use_batch_norms": [False, False, False, False, False],
            "use_layer_norms": [False, False, False, False, True],
            "is_binary_input": False,
        },
        {
            "input": 514,
            "hiddens": [512, 256, 128, 64],
            "output": 68,
            "use_biases": [True, True, True, True, True],
            "dropouts": [0.1, 0, 0, 0, 0],
            "activations": ["relu", "relu", "relu", "relu", None],
            "use_batch_norms": [False, False, False, False, False],
            "use_layer_norms": [False, False, False, False, True],
            "is_binary_input": False,
        },
    ],
    "latent_projector": {
            "input": 68,
            "hiddens": [],
            "output": 68,
            "use_biases": [True],
            "dropouts": [0],
            "activations": [None],
            "use_batch_norms": [False],
            "use_layer_norms": [False],
            "is_binary_input": False,
        },
    "decoders": [
        {
            "input": 68,
            "hiddens": [128, 256, 512, 1024],
            "output": 1252,
            "use_biases": [True, True, True, True, True],
            "dropouts": [0, 0, 0, 0, 0],
            "activations": ["relu", "relu", "relu", "relu", None],
            "use_batch_norms": [False, False, False, False, False],
            "use_layer_norms": [False, False, False, False, False],
        },
        {
            "input": 68,
            "hiddens": [128, 256, 512, 1024],
            "output": 68,
            "use_biases": [True, True, True, True, True],
            "dropouts": [0, 0, 0, 0, 0],
            "activations": ["relu", "relu", "relu", "relu", None],
            "use_batch_norms": [False, False, False, False, False],
            "use_layer_norms": [False, False, False, False, False],
        },
        {
            "input": 68,
            "hiddens": [128, 256, 512, 1024],
            "output": 514,
            "use_biases": [True, True, True, True, True],
            "dropouts": [0, 0, 0, 0, 0],
            "activations": ["relu", "relu", "relu", "relu", None],
            "use_batch_norms": [False, False, False, False, False],
            "use_layer_norms": [False, False, False, False, False],
        },
    ],
    "discriminators": [
        {
            "input": 1252,
            "hiddens": [1024, 512, 256, 128],
            "output": 68,
            "use_biases": [True, True, True, True, True],
            "dropouts": [0.5, 0, 0, 0, 0],
            "activations": ["relu", "relu", "relu", "relu", "sigmoid"],
            "use_batch_norms": [False, False, False, False, False],
            "use_layer_norms": [False, False, False, False, True],
            "is_binary_input": False,
        },
        {
            "input": 68,
            "hiddens": [1024, 512, 256, 128],
            "output": 68,
            "use_biases": [True, True, True, True, True],
            "dropouts": [0, 0, 0, 0, 0],
            "activations": ["relu", "relu", "relu", "relu", "sigmoid"],
            "use_batch_norms": [False, False, False, False, False],
            "use_layer_norms": [False, False, False, False, True],
            "is_binary_input": False,
        },
        {
            "input": 514,
            "hiddens": [512, 256, 128, 64],
            "output": 68,
            "use_biases": [True, True, True, True, True],
            "dropouts": [0.1, 0, 0, 0, 0],
            "activations": ["relu", "relu", "relu", "relu", "sigmoid"],
            "use_batch_norms": [False, False, False, False, False],
            "use_layer_norms": [False, False, False, False, True],
            "is_binary_input": False,
        },
    ],
    "projectors": {
        "input": 68,
        "hiddens": [],
        "output": 100,
        "use_biases": [True],
        "dropouts": [0],
        "activations": ['relu'],
        "use_batch_norms": [False],
        "use_layer_norms": [True],
    },
    "clusters": {
        "input": 100,
        "hiddens": [],
        "output": 27,
        "use_biases": [False],
        "dropouts": [0],
        "activations": [None],
        "use_batch_norms": [False],
        "use_layer_norms": [False],
    },
}