dbitseq_config = {'train_batch_size': 16,
       'finetune_batch_size': 16,
       'transfer_batch_size': None,
       'train_epochs': 20,
       'finetune_epochs': 10,
       'transfer_epochs': None,
       'train_task': 'cross_model_prediction_clus',
       'finetune_task': 'unsupervised_group_identification',
       'transfer_task': None,
       'train_loss_weight': None,
       'finetune_loss_weight': None,
       'transfer_loss_weight': None,
       'lr': 0.001,
       'checkpoint': 20,
       'n_head': 10,
       'noise_level': [0, 0, 0],
       'fuser_type': 'WeightedMean',
       'encoders': [{'input': 568,
                     'hiddens': [512, 256, 128, 64],
                     'output': 22,
                     'use_biases': [True, True, True, True, True],
                     'dropouts': [0, 0, 0, 0, 0],
                     'activations': ['relu', 'relu', 'relu', 'relu', None],
                     'use_batch_norms': [False, False, False, False, False],
                     'use_layer_norms': [False, False, False, False, True],
                     'is_binary_input': False},
                    {'input': 22,
                     'hiddens': [512, 256, 128, 64],
                     'output': 22,
                     'use_biases': [True, True, True, True, True],
                     'dropouts': [0, 0, 0, 0, 0],
                     'activations': ['relu', 'relu', 'relu', 'relu', None],
                     'use_batch_norms': [False, False, False, False, False],
                     'use_layer_norms': [False, False, False, False, True],
                     'is_binary_input': False},
                    {'input': 568,
                     'hiddens': [512, 256, 128, 64],
                     'output': 22,
                     'use_biases': [True, True, True, True, True],
                     'dropouts': [0, 0, 0, 0, 0],
                     'activations': ['relu', 'relu', 'relu', 'relu', None],
                     'use_batch_norms': [False, False, False, False, False],
                     'use_layer_norms': [False, False, False, False, True],
                     'is_binary_input': False}],
       'latent_projector': None,
       'decoders': [{'input': 22,
                     'hiddens': [64, 128, 256, 512],
                     'output': 568,
                     'use_biases': [True, True, True, True, True],
                     'dropouts': [0, 0, 0, 0, 0],
                     'activations': ['relu', 'relu', 'relu', 'relu', None],
                     'use_batch_norms': [False, False, False, False, False],
                     'use_layer_norms': [False, False, False, False, False]},
                    {'input': 22,
                     'hiddens': [64, 128, 256, 512],
                     'output': 22,
                     'use_biases': [True, True, True, True, True],
                     'dropouts': [0, 0, 0, 0, 0],
                     'activations': ['relu', 'relu', 'relu', 'relu', None],
                     'use_batch_norms': [False, False, False, False, False],
                     'use_layer_norms': [False, False, False, False, False]},
                    {'input': 22,
                     'hiddens': [64, 128, 256, 512],
                     'output': 568,
                     'use_biases': [True, True, True, True, True],
                     'dropouts': [0, 0, 0, 0, 0],
                     'activations': ['relu', 'relu', 'relu', 'relu', None],
                     'use_batch_norms': [False, False, False, False, False],
                     'use_layer_norms': [False, False, False, False, False]}],
       'discriminators': [{'input': 568,
                           'hiddens': [512, 256, 256],
                           'output': 1,
                           'use_biases': [True, True, True, True],
                           'dropouts': [0, 0, 0, 0, 0],
                           'activations': ['relu', 'relu', 'relu', 'sigmoid'],
                           'use_batch_norms': [False, False, False, False],
                           'use_layer_norms': [False, False, False, True]},
                          {'input': 22,
                           'hiddens': [512, 256, 256],
                           'output': 1,
                           'use_biases': [True, True, True, True],
                           'dropouts': [0, 0, 0, 0],
                           'activations': ['relu', 'relu', 'relu', 'sigmoid'],
                           'use_batch_norms': [False, False, False, False],
                           'use_layer_norms': [False, False, False, True]},
                          {'input': 568,
                           'hiddens': [512, 256, 256],
                           'output': 1,
                           'use_biases': [True, True, True, True],
                           'dropouts': [0, 0, 0, 0],
                           'activations': ['relu', 'relu', 'relu', 'sigmoid'],
                           'use_batch_norms': [False, False, False, False],
                           'use_layer_norms': [False, False, False, True]}],
       'projectors': {'input': 22,
                      'hiddens': [],
                      'output': 64,
                      'use_biases': [True],
                      'dropouts': [0],
                      'activations': ['relu'],
                      'use_batch_norms': [False],
                      'use_layer_norms': [True]},
       'clusters': {'input': 64,
                    'hiddens': [],
                    'output': 12,
                    'use_biases': [False],
                    'dropouts': [0],
                    'activations': [None],
                    'use_batch_norms': [False],
                    'use_layer_norms': [False]}
       }
