```{r}
########## data classification after Multigrate #####
library(randomForest)
library(glue)
library(rhdf5)
root_folder <- "../../../data/dataset_classification_split/"

# 列出所有数据集文件夹
datasets <- list.dirs(root_folder, full.names = TRUE, recursive = FALSE)
# 遍历每个数据集
for (dataset in datasets) {
    # 列出该数据集下的所有方法文件夹
    methods <- list.dirs(dataset, full.names = TRUE, recursive = FALSE)   
    dataset_name <- basename(dataset)
     if (dataset_name %in% c("SD11","SD12","SD13","SD14")){ #,"D42"
    for (method in methods) {
        method_name <- basename(method)
        if (method_name == "Multigrate") {
          data_files <- list.files(method, pattern = "embedding_batch[0-9]+\\.h5")
          data_files <- data_files[order(as.numeric(gsub("embedding_batch([0-9]+)\\.h5", "\\1", data_files)))]

          cty_files <- list.files(method, pattern = "cty[0-9]+\\.csv")
          cty_files <- cty_files[order(as.numeric(gsub("cty([0-9]+)\\.csv", "\\1", cty_files)))]

          k = 0
          for (i in 1:length(data_files)) {
            # 加载reference数据和标签
            reference_path <- file.path(method, data_files[i])
            reference_cty_path <- file.path(method, cty_files[i])
            reference <- h5read(reference_path, "data")
            reference_cty <- read.csv(reference_cty_path)$x
            
            # 初始化 query 数据和标签
            query_combined <- NULL
            gt_cty_combined <- NULL

            # 对于每个reference，将其他所有数据作为一个整体的query
            for (j in 1:length(data_files)) {
              if (i != j) {
                # 加载查询数据和标签
                query_path <- file.path(method, data_files[j])
                gt_cty_path <- file.path(method, cty_files[j])
                query <- h5read(query_path, "data")
                gt_cty <- read.csv(gt_cty_path)$x
                
                # 筛选出只包含 reference_cty 中存在的标签
                valid_indices <- gt_cty %in% reference_cty
                query_subset <- query[, valid_indices, drop = FALSE]
                gt_cty_subset <- gt_cty[valid_indices]
                
                # 如果筛选后还有数据，合并到总的 query 中
                if (length(gt_cty_subset) > 0) {
                  if (is.null(query_combined)) {
                    query_combined <- query_subset
                    gt_cty_combined <- gt_cty_subset
                  } else {
                    query_combined <- cbind(query_combined, query_subset)
                    gt_cty_combined <- c(gt_cty_combined, gt_cty_subset)
                  }
                }
              }
            }

            # 仅在合并了 query 数据后执行 kNN 分类
            if (!is.null(query_combined) && length(gt_cty_combined) > 0) {
              k = k + 1
              # 执行kNN分类
              rf_model <- randomForest(x = t(reference), y = as.factor(reference_cty))
              predicted_cty <- stats::predict(rf_model, t(query_combined))
              
              # 输出准确率
              accuracy <- sum(predicted_cty == gt_cty_combined) / length(gt_cty_combined)
              print(paste("Reference:", data_files[i], "- Combined Filtered Query Batches - Accuracy:", accuracy))
              save_path = glue("../../../result/classification/{dataset_name}/Multigrate_rf/r{k}")
              if (!dir.exists(save_path)) {
                dir.create(save_path, recursive = TRUE)
                print("path created")
              }
              write.csv(predicted_cty, glue("{save_path}/predict.csv"))
              write.csv(gt_cty_combined, glue("{save_path}/query.csv"))
            }
          }
        }
    }
    }
}
```





```{r}
########## data classification after Multigrate #####
library(randomForest)
library(class)
library(glue)
library(rhdf5)
root_folder <- "../../../data/dataset_classification_split/D49/Multigrate/"
dataset_name <- "D49"
# 列出所有数据集文件夹
datasets <- list.dirs(root_folder, full.names = TRUE, recursive = FALSE)
# 遍历每个数据集
for (dataset in datasets) {
    method_name <- basename(dataset)
    if (grepl("rep", method_name)) {
      data_files <- list.files(dataset, pattern = "embedding_batch[0-9]+\\.h5")
      data_files <- data_files[order(as.numeric(gsub("embedding_batch([0-9]+)\\.h5", "\\1", data_files)))]

      #cty_files <- list.files(dataset, pattern = glue("cty[0-9]+_{method_name}+\\.csv"))
      cty_files <- list.files(glue("../../../data/dataset_final_different_cty_percentage/{dataset_name}/"), pattern = glue("cty[0-9]+_{method_name}+\\.csv"))
      cty_files <- cty_files[order(as.numeric(gsub("cty([0-9]+)_rep[0-9]+\\.csv", "\\1", cty_files)))]


      k = 0
      for (i in 1:length(data_files)) {
        # 加载reference数据和标签
        reference_path <- file.path(dataset, data_files[i])
        #reference_cty_path <- file.path(dataset, cty_files[i])
        reference_cty_path <- file.path(glue("../../../data/dataset_final_different_cty_percentage/{dataset_name}/"), cty_files[i])
        reference <- h5read(reference_path, "data")
        reference_cty <- read.csv(reference_cty_path)$x
        
        # 初始化 query 数据和标签
        query_combined <- NULL
        gt_cty_combined <- NULL

        # 对于每个reference，将其他所有数据作为一个整体的query
        for (j in 1:length(data_files)) {
          if (i != j) {
            # 加载查询数据和标签
            query_path <- file.path(dataset, data_files[j])
            #gt_cty_path <- file.path(dataset, cty_files[j])
            gt_cty_path <- file.path(glue("../../../data/dataset_final_different_cty_percentage/{dataset_name}/"), cty_files[j])

            query <- h5read(query_path, "data")
            gt_cty <- read.csv(gt_cty_path)$x
            
            # 筛选出只包含 reference_cty 中存在的标签
            valid_indices <- gt_cty %in% reference_cty
            query_subset <- query[, valid_indices, drop = FALSE]
            gt_cty_subset <- gt_cty[valid_indices]
            
            # 如果筛选后还有数据，合并到总的 query 中
            if (length(gt_cty_subset) > 0) {
              if (is.null(query_combined)) {
                query_combined <- query_subset
                gt_cty_combined <- gt_cty_subset
              } else {
                query_combined <- cbind(query_combined, query_subset)
                gt_cty_combined <- c(gt_cty_combined, gt_cty_subset)
              }
            }
          }
        }

        # 仅在合并了 query 数据后执行 kNN 分类
        if (!is.null(query_combined) && length(gt_cty_combined) > 0) {
          k = k + 1
          # 执行kNN分类
              rf_model <- randomForest(x = t(reference), y = as.factor(reference_cty))
              predicted_cty <- stats::predict(rf_model, t(query_combined))
          
          # 输出准确率
          accuracy <- sum(predicted_cty == gt_cty_combined) / length(gt_cty_combined)
          print(paste("Reference:", data_files[i], "- Combined Filtered Query Batches - Accuracy:", accuracy))
          save_path = glue("../../../result/classification/{dataset_name}/Multigrate_rf/{method_name}/r{k}")
          if (!dir.exists(save_path)) {
            dir.create(save_path, recursive = TRUE)
            print("path created")
          }
          write.csv(predicted_cty, glue("{save_path}/predict.csv"))
          write.csv(gt_cty_combined, glue("{save_path}/query.csv"))
        }
      }
    }
}
```


```{r}
########## data classification after Multigrate #####
library(class)
library(glue)
library(rhdf5)
root_folder <- "../../../data/dataset_classification_split/D49/Multigrate/"
dataset_name <- "D49"
# 列出所有数据集文件夹
datasets <- list.dirs(root_folder, full.names = TRUE, recursive = FALSE)
# 遍历每个数据集
for (dataset in datasets) {
    method_name <- basename(dataset)
    if (grepl("seed", method_name)) {
      data_files <- list.files(dataset, pattern = "embedding_batch[0-9]+\\.h5")
      data_files <- data_files[order(as.numeric(gsub("embedding_batch([0-9]+)\\.h5", "\\1", data_files)))]

      cty_files <- list.files(glue("../../../data/dataset_final/{dataset_name}/"), pattern = glue("cty[0-9]\\.csv"))
      #cty_files <- list.files(dataset, pattern = "cty[0-9]+\\.csv")
      cty_files <- cty_files[order(as.numeric(gsub("cty([0-9]+)\\.csv", "\\1", cty_files)))]

      k = 0
      for (i in 1:length(data_files)) {
        # 加载reference数据和标签
        reference_path <- file.path(dataset, data_files[i])
        reference_cty_path <- file.path(glue("../../../data/dataset_final/{dataset_name}/"), cty_files[i])
        #reference_cty_path <- file.path(dataset, cty_files[i])
        reference <- h5read(reference_path, "data")
        reference_cty <- read.csv(reference_cty_path)$x
        
        # 初始化 query 数据和标签
        query_combined <- NULL
        gt_cty_combined <- NULL

        # 对于每个reference，将其他所有数据作为一个整体的query
        for (j in 1:length(data_files)) {
          if (i != j) {
            # 加载查询数据和标签
            query_path <- file.path(dataset, data_files[j])
            gt_cty_path <- file.path(glue("../../../data/dataset_final/{dataset_name}/"), cty_files[j])

            #gt_cty_path <- file.path(dataset, cty_files[j])
            query <- h5read(query_path, "data")
            gt_cty <- read.csv(gt_cty_path)$x
            
            # 筛选出只包含 reference_cty 中存在的标签
            valid_indices <- gt_cty %in% reference_cty
            query_subset <- query[, valid_indices, drop = FALSE]
            gt_cty_subset <- gt_cty[valid_indices]
            
            # 如果筛选后还有数据，合并到总的 query 中
            if (length(gt_cty_subset) > 0) {
              if (is.null(query_combined)) {
                query_combined <- query_subset
                gt_cty_combined <- gt_cty_subset
              } else {
                query_combined <- cbind(query_combined, query_subset)
                gt_cty_combined <- c(gt_cty_combined, gt_cty_subset)
              }
            }
          }
        }

        # 仅在合并了 query 数据后执行 kNN 分类
        if (!is.null(query_combined) && length(gt_cty_combined) > 0) {
          k = k + 1
          # 执行kNN分类
         predicted_cty <- knn(t(reference), t(query_combined), reference_cty, 5)
          
          # 输出准确率
          accuracy <- sum(predicted_cty == gt_cty_combined) / length(gt_cty_combined)
          print(paste("Reference:", data_files[i], "- Combined Filtered Query Batches - Accuracy:", accuracy))
          save_path = glue("../../../result/classification/{dataset_name}/Multigrate_rf/{method_name}/r{k}")
          if (!dir.exists(save_path)) {
            dir.create(save_path, recursive = TRUE)
            print("path created")
          }
          write.csv(predicted_cty, glue("{save_path}/predict.csv"))
          write.csv(gt_cty_combined, glue("{save_path}/query.csv"))
        }
      }
    }
}
```

